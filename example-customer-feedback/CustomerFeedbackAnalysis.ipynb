{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "ffeb4eee",
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "import sys\n",
                "\n",
                "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
                "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "f1a9eb90-335c-4214-8bb6-fd1edbe3ccbd",
            "metadata": {},
            "outputs": [],
            "source": [
                "# My OpenAI Key\n",
                "import os\n",
                "os.environ['OPENAI_API_KEY'] = \"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\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "8d0b2364-4806-4656-81e7-3f6e4b910b5b",
            "metadata": {},
            "outputs": [],
            "source": [
                "from llama_index import GPTTreeIndex, GPTListIndex, GPTSimpleVectorIndex, SimpleDirectoryReader\n",
                "from IPython.display import Markdown, display\n",
                "from llama_index import LLMPredictor\n",
                "from langchain.llms import OpenAIChat"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "bc76c752",
            "metadata": {},
            "outputs": [],
            "source": [
                "llm_predictor = LLMPredictor(llm=OpenAIChat(temperature=0, model_name=\"gpt-3.5-turbo\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "1298bbb4-c99e-431e-93ef-eb32c0a2fc2a",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
                        "> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
                        "INFO:root:> [build_index_from_documents] Total embedding token usage: 28155 tokens\n",
                        "> [build_index_from_documents] Total embedding token usage: 28155 tokens\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "documents = SimpleDirectoryReader('data').load_data()\n",
                "# index = GPTTreeIndex(documents, llm_predictor=llm_predictor)\n",
                "index = GPTSimpleVectorIndex(documents, llm_predictor=llm_predictor)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "0b4fe9b6-5762-4e86-b51e-aac45d3ecdb1",
            "metadata": {},
            "outputs": [],
            "source": [
                "index.save_to_disk('index_customer_review_simple_vector.json')\n",
                "new_index = GPTSimpleVectorIndex.load_from_disk('index_customer_review_simple_vector.json')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "68c9ebfe-b1b6-4f4e-9278-174346de8c90",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:root:> [query] Total LLM token usage: 3899 tokens\n",
                        "> [query] Total LLM token usage: 3899 tokens\n",
                        "INFO:root:> [query] Total embedding token usage: 18 tokens\n",
                        "> [query] Total embedding token usage: 18 tokens\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "<b>\n",
                            "1. 餐厅价格还好不是很贵，走累了对付一口\n",
                            "2. 商品的品种特别多，人也特别多，有的地方会出行拥堵\n",
                            "3. 逛完了还可以享受美食，棒棒哒\n",
                            "4. 停车场有室外和室内的，车位多，停车方便\n",
                            "5. 逛累了，桌椅板凳多的是，尽情坐\n",
                            "6. 甜品实在是不敢恭维，都太甜了\n",
                            "7.</b>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# set Logging to DEBUG for more detailed outputs\n",
                "\n",
                "response = new_index.query(\"有哪些好评, 来20个\")\n",
                "display(Markdown(f\"<b>{response}</b>\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "ca10a9c1-9dff-476d-b218-3208a1b8e7f6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:root:> [query] Total LLM token usage: 3919 tokens\n",
                        "> [query] Total LLM token usage: 3919 tokens\n",
                        "INFO:root:> [query] Total embedding token usage: 33 tokens\n",
                        "> [query] Total embedding token usage: 33 tokens\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "<b>\n",
                            "1. 减少客流量，让顾客可以轻松舒适地逛街\n",
                            "2. 提供更多的食物选择，满足不同口味的顾客\n",
                            "3. 提供更多的优惠活动，让顾客有更多的节省机会\n",
                            "4. 提供更多的休息地方，让顾客可以放松休息\n",
                            "5. 提供更多的新颖家具，让顾客有更多的选择\n",
                            "6. 提高家具的质量</b>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# GPT is confused by the text evidence\n",
                "response = new_index.query(\"基于负面评论, 有哪些改善点\")\n",
                "display(Markdown(f\"<b>{response}</b>\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "9b2c2c01",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:root:> [query] Total LLM token usage: 3785 tokens\n",
                        "> [query] Total LLM token usage: 3785 tokens\n",
                        "> [query] Total LLM token usage: 3785 tokens\n",
                        "INFO:root:> [query] Total embedding token usage: 22 tokens\n",
                        "> [query] Total embedding token usage: 22 tokens\n",
                        "> [query] Total embedding token usage: 22 tokens\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "<b>\n",
                            "夸奖主要集中在宜家家居的商品品种繁多、服务员态度好、停车方便、价格合理、节日氛围浓郁、新品多、活动多、美食百吃不厌、装修灵感多等方面。</b>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "response = new_index.query(\"夸奖主要集中在哪些方面\")\n",
                "display(Markdown(f\"<b>{response}</b>\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        },
        "vscode": {
            "interpreter": {
                "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
